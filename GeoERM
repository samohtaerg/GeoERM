## penalized GeoERM
def GeoERM(data, r = 3, T1 = 1, T2 = 1, R = None, r_bar = None, lr = 0.01, max_iter = 20, C1 = 1, C2 = 1,
            delta = 0.05, adaptive = False, info = False, tol = 1e-6, link = 'linear'):
    if info:
        print("pERM starts running...", flush = True)

    T = len(data)
    n = np.array([x.shape[0] for (x,y) in data])
    p = data[0][0].shape[1]
    n_total = np.sum(n)

    ## initialization
    x = np.zeros((n_total, p))
    y = np.zeros(n_total)

    # calculate sample indices for each task
    task_range = []
    start_index = 0
    for t in range(T):
        task_range.append(range(start_index, start_index+n[t]))
        start_index += n[t]

    # stack the x and y arrays
    for t in range(T):
        x[task_range[t], :] = data[t][0]
        y[task_range[t]] = data[t][1]

    ## r adaptive or not
    if (adaptive == True):
        # single-task linear regression
        beta_hat_single_task = np.zeros((p, T))
        if link == 'linear':
            for t in range(T):
                beta_hat_single_task[:, t] = LinearRegression(fit_intercept = False).fit(x[task_range[t], :], y[task_range[t]]).coef_
        elif link == 'logistic':
            for t in range(T):
                beta_hat_single_task[:, t] = LogisticRegression(fit_intercept = False).fit(x[task_range[t], :], y[task_range[t]]).coef_

        norm_each_task = column_norm(beta_hat_single_task)
        if R is None:
            R = np.median(norm_each_task)*2

        for t in range(T):
            if (norm_each_task[t] > R):
                beta_hat_single_task[:, t] = beta_hat_single_task[:, t]/norm_each_task[t]*R

        # set up threshold
        if r_bar is None:
            r_bar = x.shape[1]
        threshold = T1*np.sqrt((p+np.log(T))/np.max(n)) + T2*R*(r_bar**(-3/4))
        r = max(np.where(np.linalg.svd(beta_hat_single_task/np.sqrt(T))[1] > threshold)[0])+1
        if info:
            print('Selected r = ' + str(r))

    # initialization
    y = torch.tensor(y, requires_grad=False)
    x = torch.tensor(x, requires_grad=False)
    # A_hat = np.random.rand(T, p, r)#, dtype ='float64')
    # A_bar = np.random.rand(p, r)#, dtype='float64')
    A_hat = initialize_stiefel_tensor(T, p, r)
    A_bar = initialize_stiefel_matrix(p, r)
    A_bar[0:r, 0:r] = np.identity(r,dtype='float64')

    for t in range(T):
        A_hat[t, 0:r, 0:r] = np.identity(r)

    theta_hat = np.zeros((r, T))

    # transform arrays to tensors
    # A_hat = torch.tensor(A_hat, requires_grad=True)
    A_bar = torch.tensor(A_bar, requires_grad=True, dtype=torch.float64)
    A_hat = torch.tensor(A_hat, requires_grad=True, dtype=torch.float64)
    theta_hat = torch.tensor(theta_hat, requires_grad=True, dtype=torch.float64)

    ## Step 1
    lam = np.sqrt(r*(p+np.log(T)))*C1

    if link == 'linear':
        def ftotal(A, theta, A_bar):
            s = 0
            for t in range(T):
                s = s + 1/(2*n_total)*torch.dot(y[task_range[t]] - x[task_range[t], :] @ A[t, :, :] @ theta[:, t], y[task_range[t]]
                                     - x[task_range[t], :] @ A[t, :, :] @ theta[:, t]) + lam*np.sqrt(n[t])/n_total*torch.linalg.svd(A[t, :, :] @ torch.linalg.inv(A[t, :, :].T @ A[t, :, :]) @ A[t, :, :].T - A_bar @ torch.linalg.inv(A_bar.T @ A_bar) @ A_bar.T)[1][0]
            return(s)
    elif link == 'logistic':
        def ftotal(A, theta, A_bar):
            s = 0
            for t in range(T):
                logits = torch.matmul(x[task_range[t], :], A[t, :, :] @ theta[:, t])
                s = s + 1/n_total*torch.dot(1-y[task_range[t]], logits) + 1/n_total*torch.sum(torch.log(1+torch.exp(-logits))) + lam*np.sqrt(n[t])/n_total*torch.linalg.svd(A[t, :, :] @ torch.linalg.inv(A[t, :, :].T @ A[t, :, :]) @ A[t, :, :].T - A_bar @ torch.linalg.inv(A_bar.T @ A_bar) @ A_bar.T)[1][0]

            return(s)

    optimizer = optim.Adam([A_hat, theta_hat, A_bar], lr=lr)

    loss_last = 1e8
    for i in range(max_iter):
        # Zero the gradients
        optimizer.zero_grad()

        # Compute the loss (sum of the largest singular values)
        loss = ftotal(A_hat, theta_hat, A_bar)

        # Backward pass to compute gradients
        loss.backward()
        # print(A_bar.grad)

        # Projection on gradients
        projected_A_hat_grad = projection(A_hat, A_hat.grad)
        projected_A_bar_grad = projection(A_bar, A_bar.grad)

        # Update the gradients to their projected versions
        with torch.no_grad():
            A_hat.grad.copy_(projected_A_hat_grad)
            A_bar.grad.copy_(projected_A_bar_grad)

        # Update the matrices with Adam
        optimizer.step()
        # print(A_bar.grad)

        with torch.no_grad():
            A_hat.copy_(polar_retraction(A_hat))
            A_bar.copy_(polar_retraction(A_bar))
        # with torch.no_grad():
        #     A_hat.copy_(R(A_hat))
        #     A_bar.copy_(R(A_bar))

        # Loss
        if info:
            if (i + 1) % 100 == 0:
                print("Iteration {}/{}, Loss: {}".format(i+1, max_iter, loss.item()), flush=True)

        # Early Stop
        if abs(loss_last - loss.item()) / loss.item() <= tol:
            if info:
                print("Already converged. Stopped early.", flush=True)
            break
        loss_last = loss.item()

    beta_hat_step1 = torch.zeros(p, T, dtype=torch.float64)
    for t in range(T):
        beta_hat_step1[:, t] = A_hat[t, :, :] @ theta_hat[:, t]

    beta_hat_step1 = beta_hat_step1.detach()
    if info:
        print("Step 1 is completed.\n", flush=True)

    ## Step 2
    gamma = np.sqrt(p+np.log(T))*C2
    beta = torch.zeros(p, T, requires_grad = True, dtype=torch.float64)

    if link == 'linear':
        def ftotal2(beta):
            s = 0
            for t in range(T):
                s = s + 1/(2*n[t])*torch.dot(y[task_range[t]] - x[task_range[t], :] @ beta[:, t], y[task_range[t]] - x[task_range[t], :] @ beta[:, t]) + gamma/np.sqrt(n[t])*torch.norm(beta[:, t] - beta_hat_step1[:, t])
            return(s)
    elif link == 'logistic':
        def ftotal2(beta):
            s = 0
            for t in range(T):
                logits = torch.matmul(x[task_range[t], :], beta[:, t])
                s = s + 1/n[t]*torch.dot(1-y[task_range[t]], logits) + 1/n[t]*torch.sum(torch.log(1+torch.exp(-logits))) + gamma/np.sqrt(n[t])*torch.norm(beta[:, t] - beta_hat_step1[:, t])
            return(s)


    optimizer2 = optim.Adam([beta], lr=lr)
    loss_last = 1e8
    for i in range(max_iter):
        # Zero the gradients
        optimizer2.zero_grad()

        # Compute the loss (sum of the largest singular values)
        loss2 = ftotal2(beta)

        # Backward pass to compute gradients
        loss2.backward()

        # Update the matrices
        optimizer2.step()

        # Print the loss every 100 iterations
        if info:
            if (i + 1) % 100 == 0:
                print("Iteration {}/{}, Loss: {}".format(i+1, max_iter, loss2.item()), flush = True)
        if abs(loss_last-loss2.item())/loss2.item() <= tol:
            if info:
                print("Already converged. Stopped early.", flush = True)
            break
        loss_last = loss2.item()

    beta_hat_step1 = beta_hat_step1.numpy()
    beta_hat_step2 = beta.detach().numpy()
    if info:
        print("Step 2 is completed.\n", flush = True)

    if info:
        print("GeoERM stops running...", flush = True)

    return({"step1": beta_hat_step1, "step2": beta_hat_step2})
